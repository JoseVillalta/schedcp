{
  "schedulers": [
    {
      "name": "scx_bpfland",
      "production_ready": true,
      "description": "A vruntime-based sched_ext scheduler that prioritizes interactive workloads by detecting tasks with high voluntary context switch rates. Tasks are categorized as interactive or regular based on their average rate of voluntary context switches per second. Interactive tasks are prioritized in a higher-priority queue with weighted runtime scheduling. Each task gets a time slice budget that carries over unused portions, benefiting latency-sensitive workloads like real-time audio.",
      "use_cases": [
        "gaming",
        "live_streaming",
        "multimedia",
        "real_time_audio"
      ],
      "algorithm": "vruntime_based",
      "characteristics": "interactive task prioritization, voluntary context switch detection, weighted runtime queuing, time slice budget carryover, cpu frequency control, cache topology awareness",
      "tuning_parameters": {
        "slice_us": {
          "type": "integer",
          "description": "Maximum scheduling slice duration in microseconds",
          "default": 20000,
          "range": [1000, 100000]
        },
        "slice_us_min": {
          "type": "integer",
          "description": "Minimum scheduling slice duration in microseconds",
          "default": 1000,
          "range": [100, 10000]
        },
        "slice_us_lag": {
          "type": "integer",
          "description": "Maximum time slice lag in microseconds",
          "default": 20000,
          "range": [-100000, 100000]
        },
        "throttle_us": {
          "type": "integer",
          "description": "CPU throttling period in microseconds",
          "default": 0,
          "range": [0, 1000000]
        },
        "idle_resume_us": {
          "type": "integer",
          "description": "CPU idle QoS resume latency in microseconds",
          "default": -1,
          "range": [-1, 1000000]
        },
        "no_preempt": {
          "type": "boolean",
          "description": "Disable preemption",
          "default": false
        },
        "local_pcpu": {
          "type": "boolean",
          "description": "Enable per-CPU tasks prioritization",
          "default": false
        },
        "local_kthreads": {
          "type": "boolean",
          "description": "Enable kthreads prioritization (EXPERIMENTAL)",
          "default": false
        },
        "primary_domain": {
          "type": "string",
          "description": "CPU domain configuration (auto/performance/powersave/all/none)",
          "default": "auto"
        },
        "cpufreq": {
          "type": "boolean",
          "description": "Enable CPU frequency control",
          "default": false
        }
      },
      "limitations": "May not optimize for pure batch workloads, experimental kthread prioritization",
      "performance_profile": "optimized for low latency and interactive responsiveness"
    },
    {
      "name": "scx_central",
      "production_ready": false,
      "description": "A central scheduler where all scheduling decisions are made from a single CPU, allowing other cores to run with infinite slices without timer ticks. This design reduces scheduling overhead by concentrating all scheduling logic on one designated CPU while worker CPUs simply execute tasks. Tasks are preempted every 20ms via timer callback.",
      "use_cases": [
        "virtualization",
        "low_latency",
        "vm_workloads"
      ],
      "algorithm": "central_dispatch",
      "characteristics": "single cpu dispatch, infinite slices, timer tick reduction, fifo ordering, 20ms preemption timer",
      "tuning_parameters": {
        "central_cpu": {
          "type": "integer",
          "description": "CPU ID to use for central scheduling",
          "default": 0,
          "range": [0, 255]
        },
        "slice_us": {
          "type": "integer",
          "description": "Override slice duration in microseconds",
          "default": 20000,
          "range": [1000, 100000]
        }
      },
      "limitations": "Not production ready, no priority mechanism, fixed 20ms preemption",
      "performance_profile": "reduced scheduling overhead on worker CPUs"
    },
    {
      "name": "scx_chaos",
      "production_ready": false,
      "description": "A chaos testing scheduler based on scx_p2dq that introduces controlled randomness to stress test scheduling behavior and identify race conditions. Designed to amplify race conditions and test system stability under adverse scheduling conditions.",
      "use_cases": [
        "stress_testing",
        "debugging",
        "race_condition_detection"
      ],
      "algorithm": "p2dq_with_chaos",
      "characteristics": "chaos injection, random delays, performance degradation, cpu frequency manipulation, kprobe-based delays",
      "tuning_parameters": {
        "random_delay_frequency": {
          "type": "float",
          "description": "Chance of randomly delaying a process",
          "default": 0.0,
          "range": [0.0, 1.0]
        },
        "random_delay_min_us": {
          "type": "integer",
          "description": "Minimum time to add for random delay",
          "default": 0
        },
        "random_delay_max_us": {
          "type": "integer",
          "description": "Maximum time to add for random delay",
          "default": 1000
        },
        "degradation_frequency": {
          "type": "float",
          "description": "Chance of degrading a process",
          "default": 0.0,
          "range": [0.0, 1.0]
        },
        "min_slice_us": {
          "type": "integer",
          "description": "Minimum scheduling slice duration",
          "default": 100
        },
        "dumb_queues": {
          "type": "integer",
          "description": "Number of dumb DSQs",
          "default": 3
        }
      },
      "limitations": "Not production ready, intentionally unpredictable performance",
      "performance_profile": "designed for stress testing, not performance"
    },
    {
      "name": "scx_flash",
      "production_ready": true,
      "description": "An EDF (Earliest Deadline First) scheduler that assigns dynamic latency weights based on CPU usage patterns. Tasks that release CPU early receive higher latency weights, prioritizing them over tasks that consume full time slices. Deadlines are calculated as vruntime + exec_vruntime, ensuring fairness while prioritizing latency-sensitive tasks.",
      "use_cases": [
        "multimedia",
        "real_time_audio",
        "predictable_performance",
        "latency_sensitive"
      ],
      "algorithm": "EDF",
      "characteristics": "dynamic latency weights, early cpu release priority, fairness focused, vruntime tracking, exec_vruntime accounting, voluntary context switch credits",
      "tuning_parameters": {
        "slice_us": {
          "type": "integer",
          "description": "Maximum scheduling slice duration",
          "default": 4096,
          "range": [128, 20000]
        },
        "slice_us_min": {
          "type": "integer",
          "description": "Minimum scheduling slice duration",
          "default": 128,
          "range": [32, 4096]
        },
        "slice_us_lag": {
          "type": "integer",
          "description": "Maximum runtime budget accumulation while sleeping",
          "default": 4096
        },
        "run_us_lag": {
          "type": "integer",
          "description": "Maximum runtime penalty accumulation while running",
          "default": 32768
        },
        "max_avg_nvcsw": {
          "type": "integer",
          "description": "Maximum rate of voluntary context switches",
          "default": 128
        },
        "cpu_busy_thresh": {
          "type": "integer",
          "description": "CPU utilization threshold for busy detection (-1 = auto)",
          "default": -1
        },
        "tickless": {
          "type": "boolean",
          "description": "Enable tickless mode",
          "default": false
        },
        "rr_sched": {
          "type": "boolean",
          "description": "Enable round-robin scheduling",
          "default": false
        },
        "local_pcpu": {
          "type": "boolean",
          "description": "Enable per-CPU tasks prioritization",
          "default": false
        }
      },
      "limitations": "May not optimize for pure throughput, complex latency weight tuning",
      "performance_profile": "optimized for low latency and predictable performance"
    },
    {
      "name": "scx_flatcg",
      "production_ready": true,
      "description": "A high-performance cgroup-aware scheduler that flattens the cgroup hierarchy for better performance. It implements hierarchical weight-based cgroup CPU control by compounding active weight shares at each level into a single flat structure, eliminating tree traversal overhead during scheduling decisions.",
      "use_cases": [
        "container_workloads",
        "resource_management",
        "multi_tenant_systems"
      ],
      "algorithm": "flattened_cgroup_hierarchy",
      "characteristics": "cgroup hierarchy flattening, weight compounding, performance optimization, dual mode operation (vtime/fifo), low scheduling overhead",
      "tuning_parameters": {
        "slice_us": {
          "type": "integer",
          "description": "Override slice duration in microseconds",
          "default": 20000,
          "range": [1000, 100000]
        },
        "interval": {
          "type": "integer",
          "description": "Report interval in seconds",
          "default": 1
        },
        "fifo": {
          "type": "boolean",
          "description": "Use FIFO scheduling instead of weighted vtime",
          "default": false
        }
      },
      "limitations": "Limited to cgroup use cases, thundering herd issues possible",
      "performance_profile": "optimized for low overhead cgroup scheduling"
    },
    {
      "name": "scx_lavd",
      "production_ready": true,
      "description": "A sophisticated latency-aware scheduler implementing LAVD (Latency-criticality Aware Virtual Deadline) algorithm. It measures task latency criticality and uses virtual deadline scheduling with per-LLC domains, core type awareness, and NUMA awareness. Designed for gaming and interactive workloads on single CCX/socket systems.",
      "use_cases": [
        "gaming",
        "interactive_applications",
        "low_latency"
      ],
      "algorithm": "LAVD",
      "characteristics": "latency criticality measurement, virtual deadline scheduling, per llc domains, core type awareness, numa awareness, autopilot mode, power profile integration",
      "tuning_parameters": {
        "slice_max_us": {
          "type": "integer",
          "description": "Maximum scheduling slice duration",
          "default": 5000,
          "range": [500, 20000]
        },
        "slice_min_us": {
          "type": "integer",
          "description": "Minimum scheduling slice duration",
          "default": 500,
          "range": [100, 5000]
        },
        "preempt_shift": {
          "type": "integer",
          "description": "Preemption ratio control (top 0.5^N * 100% tasks)",
          "default": 6
        },
        "autopilot": {
          "type": "boolean",
          "description": "Automatically decide power mode and CPU preferences",
          "default": true
        },
        "performance": {
          "type": "boolean",
          "description": "Run in performance mode",
          "default": false
        },
        "powersave": {
          "type": "boolean",
          "description": "Run in powersave mode",
          "default": false
        },
        "balanced": {
          "type": "boolean",
          "description": "Run in balanced mode",
          "default": false
        },
        "no_core_compaction": {
          "type": "boolean",
          "description": "Disable core compaction",
          "default": false
        },
        "no_freq_scaling": {
          "type": "boolean",
          "description": "Disable CPU frequency control",
          "default": false
        }
      },
      "limitations": "Complex configuration, mainly targets single CCX/socket systems",
      "performance_profile": "optimized for low latency and interactivity"
    },
    {
      "name": "scx_layered",
      "production_ready": true,
      "description": "A highly configurable multi-layer scheduler that allows creating custom layers with different scheduling policies. Tasks are classified into layers based on matches (cgroup, comm, nice, etc.) and each layer can have different policies (Confined, Grouped, Open) with specific CPU utilization guarantees and topology awareness.",
      "use_cases": [
        "custom_applications",
        "priority_services",
        "complex_workloads"
      ],
      "algorithm": "layer_based",
      "characteristics": "task classification, multiple scheduling policies, cpu utilization guarantees, topology awareness, performance control, numa node affinity, llc affinity, dynamic layer sizing",
      "tuning_parameters": {
        "config_file": {
          "type": "string",
          "description": "JSON configuration file defining layers",
          "default": "none"
        },
        "slice_us": {
          "type": "integer",
          "description": "Default scheduling slice duration",
          "default": 20000,
          "range": [1000, 100000]
        },
        "max_exec_us": {
          "type": "integer",
          "description": "Maximum consecutive execution time",
          "default": 0
        },
        "interval": {
          "type": "float",
          "description": "Scheduling interval in seconds",
          "default": 0.1
        },
        "disable_topology": {
          "type": "boolean",
          "description": "Disable topology awareness",
          "default": false
        },
        "xnuma_preemption": {
          "type": "boolean",
          "description": "Enable cross NUMA preemption",
          "default": false
        },
        "antistall_sec": {
          "type": "integer",
          "description": "Maximum runnable_at delay before antistall",
          "default": 3
        }
      },
      "limitations": "Complex configuration required, potential infeasible weights issue",
      "performance_profile": "highly customizable based on layer configuration"
    },
    {
      "name": "scx_mitosis",
      "production_ready": false,
      "description": "A dynamic affinity scheduler implementing cell-based scheduling architecture. Dynamically assigns cgroups to 'cells' which are mapped to specific CPU sets. Cells can be merged or split based on system conditions, with vtime-based scheduling within each cell.",
      "use_cases": [
        "dynamic_affinity",
        "cgroup_isolation",
        "experimental"
      ],
      "algorithm": "cell_based_vtime",
      "characteristics": "dynamic cell management, adaptive cpu assignment, cgroup awareness, vtime scheduling, numa awareness, cell splitting/merging",
      "tuning_parameters": {
        "reconfiguration_interval_s": {
          "type": "integer",
          "description": "Interval to consider reconfiguring cells",
          "default": 10
        },
        "rebalance_cpus_interval_s": {
          "type": "integer",
          "description": "Interval to rebalance CPUs to cells",
          "default": 5
        },
        "monitor_interval_s": {
          "type": "integer",
          "description": "Interval to report monitoring information",
          "default": 1
        }
      },
      "limitations": "Experimental scheduler, not production ready",
      "performance_profile": "experimental dynamic affinity management"
    },
    {
      "name": "scx_nest",
      "production_ready": true,
      "description": "A frequency-optimized scheduler that keeps tasks on warm cores to maintain high CPU frequencies. Based on the Inria-Paris Nest paper, it divides cores into primary and reserve nests, concentrating work on a subset of cores to maximize boost frequencies. Best suited for single CCX/socket systems with low to moderate CPU utilization.",
      "use_cases": [
        "low_cpu_utilization",
        "frequency_sensitive",
        "latency_sensitive",
        "power_efficiency"
      ],
      "algorithm": "warm_core_clustering",
      "characteristics": "warm core prioritization, frequency optimization, single ccx limitation, cache locality awareness, dynamic nest sizing, hyperthreading awareness",
      "tuning_parameters": {
        "delay_us": {
          "type": "integer",
          "description": "Delay before removing idle core from primary nest",
          "default": 2000,
          "range": [100, 100000]
        },
        "r_max": {
          "type": "integer",
          "description": "Maximum number of cores in reserve nest",
          "default": 5,
          "range": [1, 64]
        },
        "iters": {
          "type": "integer",
          "description": "Placement failures before aggressive expansion",
          "default": 2,
          "range": [0, 10]
        },
        "slice_us": {
          "type": "integer",
          "description": "Override slice duration",
          "default": 20000
        },
        "prefer_idle": {
          "type": "boolean",
          "description": "Prefer fully idle cores over siblings",
          "default": false
        }
      },
      "limitations": "Limited to single CCX, not good for high CPU utilization",
      "performance_profile": "optimized for frequency boost and power efficiency"
    },
    {
      "name": "scx_p2dq",
      "production_ready": true,
      "description": "A versatile scheduler with multi-layer queuing using pick-two load balancing. Implements slice-based task classification to automatically detect interactive vs batch tasks. Features configurable time slices and load balancing across LLC domains with interactive task prioritization.",
      "use_cases": [
        "interactive",
        "batch_processing",
        "server_applications",
        "general_purpose"
      ],
      "algorithm": "pick_two_load_balancing",
      "characteristics": "multi layer queuing, slice based classification, interactive detection, load balancing across llc, configurable time slices, pick two algorithm",
      "tuning_parameters": {
        "nr_queues": {
          "type": "integer",
          "description": "Number of dispatch queues",
          "default": 8,
          "range": [2, 16]
        },
        "slice_us": {
          "type": "integer",
          "description": "Base time slice duration",
          "default": 20000,
          "range": [5000, 100000]
        },
        "interactive_ratio": {
          "type": "float",
          "description": "Ratio of interactive to batch tasks",
          "default": 0.5,
          "range": [0.0, 1.0]
        },
        "deadline": {
          "type": "boolean",
          "description": "Enable deadline scheduling",
          "default": false
        },
        "freq_control": {
          "type": "boolean",
          "description": "Enable CPU frequency control",
          "default": false
        }
      },
      "limitations": "May need tuning for specific workloads, complex queue management",
      "performance_profile": "balanced for mixed workloads"
    },
    {
      "name": "scx_pair",
      "production_ready": false,
      "description": "A sibling scheduler ensuring tasks only co-locate on a physical core if they're in the same cgroup. Demonstrates how to implement security mitigations for CPU bugs like L1TF by enforcing strict cgroup isolation on SMT siblings. Uses scx_bpf_kick_cpu() to preempt siblings when constraints are violated.",
      "use_cases": [
        "security_mitigation",
        "smt_isolation",
        "educational"
      ],
      "algorithm": "cgroup_based_pairing",
      "characteristics": "strict cgroup isolation, smt aware scheduling, cpu sibling pairing, security focused, educational demonstration",
      "tuning_parameters": {
        "stride": {
          "type": "integer",
          "description": "Override CPU pair stride",
          "default": -1
        }
      },
      "limitations": "Not production ready, demonstration scheduler only",
      "performance_profile": "security focused, not performance optimized"
    },
    {
      "name": "scx_prev",
      "production_ready": false,
      "description": "A variation on scx_simple that prioritizes selecting an idle previous CPU over finding fully idle cores. This optimization leverages CPU cache locality by preferring the previous CPU when possible, reducing cache misses. Particularly effective for OLTP workloads on simple topology systems.",
      "use_cases": [
        "oltp_workloads",
        "cache_sensitive",
        "simple_topology"
      ],
      "algorithm": "previous_cpu_priority",
      "characteristics": "previous cpu priority, cache locality optimization, simple and efficient, statistics tracking",
      "tuning_parameters": {
        "interval": {
          "type": "integer",
          "description": "Sampling interval for statistics in seconds",
          "default": 1
        }
      },
      "limitations": "Not extensively tested in production, best for simple topology",
      "performance_profile": "optimized for cache locality"
    },
    {
      "name": "scx_qmap",
      "production_ready": false,
      "description": "A simple five-level FIFO queue scheduler demonstrating fundamental sched_ext features. Tasks are distributed across five priority queues based on their compound weight, with weighted dispatch giving more opportunities to higher priority queues. Includes core scheduling support and CPU performance scaling.",
      "use_cases": [
        "demonstration",
        "testing",
        "educational"
      ],
      "algorithm": "five_level_fifo",
      "characteristics": "five level priority queuing, weighted dispatch, sleepable task storage, core scheduling support, cpu performance scaling, bpf map demonstration",
      "tuning_parameters": {
        "slice_us": {
          "type": "integer",
          "description": "Override slice duration",
          "default": 20000
        },
        "batch_count": {
          "type": "integer",
          "description": "Dispatch up to COUNT tasks together",
          "default": 1
        },
        "boost_nice": {
          "type": "boolean",
          "description": "Boost nice -20 tasks",
          "default": false
        }
      },
      "limitations": "Not production ready, simplified design for demonstration",
      "performance_profile": "demonstration scheduler, not optimized"
    },
    {
      "name": "scx_rlfifo",
      "production_ready": false,
      "description": "A simple Round-Robin scheduler running in user-space based on scx_rustland_core framework. Dequeues tasks in FIFO order and assigns dynamic time slices to achieve basic Round-Robin behavior. Provided as a template for testing more complex scheduling policies.",
      "use_cases": [
        "template",
        "testing",
        "educational"
      ],
      "algorithm": "user_space_round_robin",
      "characteristics": "user space scheduling, fifo ordering, dynamic time slices, rustland core based, simple template",
      "tuning_parameters": {},
      "limitations": "Not production ready, use kernel SCHED_FIFO for real-time needs",
      "performance_profile": "basic round-robin, not performance optimized"
    },
    {
      "name": "scx_rustland",
      "production_ready": false,
      "description": "A user-space scheduler written in Rust that prioritizes interactive workloads. Scheduling decisions are made entirely in user-space using a deadline-based algorithm (vruntime + exec_runtime). Tasks are stored in a BTreeSet and dispatched from lowest to highest deadline, favoring latency-sensitive tasks that frequently sleep.",
      "use_cases": [
        "gaming",
        "video_conferencing",
        "live_streaming",
        "interactive_applications"
      ],
      "algorithm": "user_space_deadline",
      "characteristics": "full user space implementation, deadline based ordering, vruntime tracking, exec runtime accounting, interactive prioritization, rust implementation",
      "tuning_parameters": {
        "slice_us": {
          "type": "integer",
          "description": "Scheduling slice duration",
          "default": 20000,
          "range": [1000, 100000]
        },
        "slice_us_min": {
          "type": "integer",
          "description": "Minimum slice duration",
          "default": 1000,
          "range": [100, 10000]
        },
        "percpu_local": {
          "type": "boolean",
          "description": "Dispatch per-CPU tasks directly",
          "default": false
        },
        "partial": {
          "type": "boolean",
          "description": "Only switch SCHED_EXT tasks",
          "default": false
        }
      },
      "limitations": "User-space overhead, not ideal for performance-critical scenarios",
      "performance_profile": "optimized for interactivity over raw performance"
    },
    {
      "name": "scx_sdt",
      "production_ready": false,
      "description": "A simple demonstration scheduler showcasing BPF arena usage for per-task data management. Implements basic FIFO scheduling while tracking detailed statistics about task lifecycle and scheduling decisions using the BPF arena allocator system.",
      "use_cases": [
        "bpf_arena_demo",
        "educational",
        "testing"
      ],
      "algorithm": "simple_fifo_with_stats",
      "characteristics": "bpf arena demonstration, per task data management, statistics collection, simple fifo scheduling, arena allocation showcase",
      "tuning_parameters": {},
      "limitations": "Educational scheduler only, minimal scheduling logic",
      "performance_profile": "demonstration scheduler, not performance focused"
    },
    {
      "name": "scx_simple",
      "production_ready": true,
      "description": "A simple scheduler with minimal complexity supporting both weighted vtime and FIFO modes. Optimized for single socket systems with uniform L3 cache. Provides a straightforward scheduling implementation suitable for systems where simplicity is preferred over advanced features.",
      "use_cases": [
        "single_socket",
        "uniform_l3_cache",
        "simple_workloads"
      ],
      "algorithm": "simple_vtime_or_fifo",
      "characteristics": "dual mode operation, minimal complexity, single socket optimized, starvation risk in fifo, straightforward implementation",
      "tuning_parameters": {
        "fifo": {
          "type": "boolean",
          "description": "Use FIFO mode instead of vtime",
          "default": false
        },
        "slice_us": {
          "type": "integer",
          "description": "Time slice duration",
          "default": 20000,
          "range": [1000, 100000]
        }
      },
      "limitations": "Limited scalability, may not optimize complex workloads",
      "performance_profile": "simple and predictable performance"
    },
    {
      "name": "scx_tickless",
      "production_ready": false,
      "description": "An experimental server-oriented scheduler designed to reduce OS noise by minimizing timer ticks. Routes all scheduling events through a pool of primary CPUs, allowing other CPUs to run tickless. Requires kernel booted with nohz_full for full effectiveness. Designed for cloud computing, virtualization, and HPC workloads.",
      "use_cases": [
        "cloud_computing",
        "virtualization",
        "hpc",
        "server_workloads"
      ],
      "algorithm": "primary_cpu_distribution",
      "characteristics": "tick reduction, primary cpu pool, os noise reduction, global task queue, configurable frequency, nohz full requirement, ipc based preemption",
      "tuning_parameters": {
        "primary_domain": {
          "type": "string",
          "description": "CPU mask for primary scheduling CPUs (hex)",
          "default": "0x1"
        },
        "slice_us": {
          "type": "integer",
          "description": "Maximum scheduling slice duration",
          "default": 20000
        },
        "frequency": {
          "type": "integer",
          "description": "Scheduling frequency (0 = CONFIG_HZ)",
          "default": 0
        },
        "prefer_same_cpu": {
          "type": "boolean",
          "description": "Try to keep tasks on same CPU",
          "default": false
        },
        "nosmt": {
          "type": "boolean",
          "description": "Disable SMT topology awareness",
          "default": false
        }
      },
      "requirements": "Linux kernel with nohz_full support",
      "limitations": "Not production ready, experimental, syscall overhead with nohz_full",
      "performance_profile": "optimized for reduced OS noise, not latency"
    },
    {
      "name": "scx_userland",
      "production_ready": false,
      "description": "A fully user-space scheduler for educational purposes demonstrating user-space scheduling concepts. All scheduling decisions are made in user-space with an ordered list scheduling approach. While offering development advantages, it has inherent performance overhead and deadlock risks.",
      "use_cases": [
        "demonstration",
        "educational",
        "prototyping"
      ],
      "algorithm": "user_space_vtime",
      "characteristics": "full user space implementation, ordered list scheduling, development advantages, deadlock risk, performance overhead, educational focus",
      "tuning_parameters": {
        "slice_us": {
          "type": "integer",
          "description": "Time slice duration",
          "default": 20000
        }
      },
      "limitations": "Not production ready, performance overhead, potential deadlocks",
      "performance_profile": "educational scheduler with significant overhead"
    },
    {
      "name": "scx_wd40",
      "production_ready": false,
      "description": "An experimental fork of scx_rusty using BPF arenas for direct memory sharing between kernel and userspace. Implements multi-domain scheduling with BPF-side round robin and userspace load balancing. Demonstrates modular scheduler design with separate components for placement, deadline tracking, and load balancing.",
      "use_cases": [
        "bpf_arena_research",
        "modular_design_demo",
        "experimental"
      ],
      "algorithm": "multi_domain_with_arenas",
      "characteristics": "bpf arena memory sharing, modular bpf design, cache aware domains, two tier load balancing, greedy work stealing, deadline tracking, numa aware operations",
      "tuning_parameters": {
        "slice_us_underutil": {
          "type": "integer",
          "description": "Slice duration for under-utilized hosts",
          "default": 20000
        },
        "slice_us_overutil": {
          "type": "integer",
          "description": "Slice duration for over-utilized hosts",
          "default": 1000
        },
        "interval": {
          "type": "float",
          "description": "Load balance interval in seconds",
          "default": 2.0
        },
        "tune_interval": {
          "type": "float",
          "description": "Tuning interval in seconds",
          "default": 0.1
        },
        "cache_level": {
          "type": "integer",
          "description": "Cache level for domain building",
          "default": 3
        },
        "greedy_threshold": {
          "type": "integer",
          "description": "Enable greedy task stealing threshold",
          "default": 1
        },
        "greedy_threshold_x_numa": {
          "type": "integer",
          "description": "Enable greedy stealing across NUMA",
          "default": 0
        }
      },
      "limitations": "Requires bleeding-edge kernel, experimental BPF arenas, not production tested",
      "performance_profile": "experimental with focus on modular design"
    },
    {
      "name": "scx_rusty",
      "production_ready": true,
      "description": "A production-ready multi-domain scheduler with intelligent load balancing. Creates separate scheduling domains per LLC with user-space load balancing. Features configurable thresholds, greedy task stealing, and support for both FIFO and priority-based scheduling within domains. Architecture-flexible design suitable for various CPU topologies.",
      "use_cases": [
        "general_purpose",
        "multi_architecture",
        "server_workloads"
      ],
      "algorithm": "multi_domain_round_robin",
      "characteristics": "multi domain support, per llc domains, user space load balancing, configurable thresholds, architecture flexibility, greedy task stealing, fifo mode support",
      "tuning_parameters": {
        "slice_us": {
          "type": "integer",
          "description": "Time slice duration in microseconds",
          "default": 20000,
          "range": [1000, 100000]
        },
        "greedy_threshold": {
          "type": "integer",
          "description": "Threshold for greedy task stealing",
          "default": 2,
          "range": [1, 10]
        },
        "kthreads": {
          "type": "boolean",
          "description": "Schedule kernel threads",
          "default": false
        },
        "fifo_sched": {
          "type": "boolean",
          "description": "Use FIFO scheduling within domains",
          "default": false
        },
        "load_half_life": {
          "type": "float",
          "description": "Load averaging half-life in seconds",
          "default": 0.5
        },
        "numa_migration": {
          "type": "boolean",
          "description": "Allow NUMA node migrations",
          "default": true
        }
      },
      "limitations": "May not distinguish NUMA nodes well, potential infeasible weights issue",
      "performance_profile": "balanced general-purpose performance"
    }
  ]
}