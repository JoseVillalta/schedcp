{
  "default": {
    "pp_tps": 180.796809,
    "tg_tps": 97.454467,
    "pp_time": 1611.28798208,
    "tg_time": 0.010264464,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:26:13Z",
        "avg_ns": 3147046840,
        "stddev_ns": 1360680668,
        "avg_ts": 180.796809,
        "stddev_ts": 62.893555,
        "samples_ns": [
          2433515817,
          4716085830,
          2291538875
        ],
        "samples_ts": [
          210.395,
          108.565,
          223.431
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:26:26Z",
        "avg_ns": 10264464,
        "stddev_ns": 225046,
        "avg_ts": 97.454467,
        "stddev_ts": 2.11919,
        "samples_ns": [
          10513764,
          10203240,
          10076389
        ],
        "samples_ts": [
          95.1134,
          98.0081,
          99.2419
        ]
      }
    ],
    "scheduler": "default",
    "exit_code": 0
  },
  "scx_bpfland": {
    "pp_tps": 275.479155,
    "tg_tps": 97.599466,
    "pp_time": 951.841485824,
    "tg_time": 0.010255528,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:26:28Z",
        "avg_ns": 1859065402,
        "stddev_ns": 36718824,
        "avg_ts": 275.479155,
        "stddev_ts": 5.464742,
        "samples_ns": [
          1864339159,
          1892862199,
          1819994848
        ],
        "samples_ts": [
          274.628,
          270.49,
          281.319
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:26:36Z",
        "avg_ns": 10255528,
        "stddev_ns": 387682,
        "avg_ts": 97.599466,
        "stddev_ts": 3.614093,
        "samples_ns": [
          10701108,
          10070038,
          9995438
        ],
        "samples_ts": [
          93.4483,
          99.3045,
          100.046
        ]
      }
    ],
    "scheduler": "scx_bpfland",
    "exit_code": 0
  },
  "scx_central": {
    "pp_tps": 256.969805,
    "tg_tps": 87.782343,
    "pp_time": 1022.552531968,
    "tg_time": 0.01152152,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:26:41Z",
        "avg_ns": 1997172914,
        "stddev_ns": 120738004,
        "avg_ts": 256.969805,
        "stddev_ts": 15.07354,
        "samples_ns": [
          1947434702,
          1909249075,
          2134834965
        ],
        "samples_ts": [
          262.91,
          268.168,
          239.831
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:26:49Z",
        "avg_ns": 11521520,
        "stddev_ns": 1505456,
        "avg_ts": 87.782343,
        "stddev_ts": 11.376594,
        "samples_ns": [
          10084135,
          13086865,
          11393562
        ],
        "samples_ts": [
          99.1657,
          76.4125,
          87.7689
        ]
      }
    ],
    "scheduler": "scx_central",
    "exit_code": 0
  },
  "scx_chaos": {
    "pp_tps": 186.800407,
    "tg_tps": 99.137311,
    "pp_time": 1411.327287808,
    "tg_time": 0.010088144,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:26:53Z",
        "avg_ns": 2756498609,
        "stddev_ns": 260814734,
        "avg_ts": 186.800407,
        "stddev_ts": 16.765471,
        "samples_ns": [
          2596386583,
          2615653225,
          3057456020
        ],
        "samples_ts": [
          197.197,
          195.745,
          167.459
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:04Z",
        "avg_ns": 10088144,
        "stddev_ns": 130889,
        "avg_ts": 99.137311,
        "stddev_ts": 1.278196,
        "samples_ns": [
          10235898,
          9986909,
          10041626
        ],
        "samples_ts": [
          97.6954,
          100.131,
          99.5855
        ]
      }
    ],
    "scheduler": "scx_chaos",
    "exit_code": 0
  },
  "scx_flash": {
    "pp_tps": 268.393263,
    "tg_tps": 100.049384,
    "pp_time": 978.02846208,
    "tg_time": 0.009999615,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:09Z",
        "avg_ns": 1910211840,
        "stddev_ns": 85954473,
        "avg_ts": 268.393263,
        "stddev_ts": 12.010016,
        "samples_ns": [
          1828766817,
          1901809992,
          2000058711
        ],
        "samples_ts": [
          279.97,
          269.217,
          255.992
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:17Z",
        "avg_ns": 9999615,
        "stddev_ns": 263160,
        "avg_ts": 100.049384,
        "stddev_ts": 2.595349,
        "samples_ns": [
          9874234,
          10302020,
          9822591
        ],
        "samples_ts": [
          101.274,
          97.0683,
          101.806
        ]
      }
    ],
    "scheduler": "scx_flash",
    "exit_code": 0
  },
  "scx_flatcg": {
    "pp_tps": 252.042156,
    "tg_tps": 99.553335,
    "pp_time": 1040.569026048,
    "tg_time": 0.010045437,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:22Z",
        "avg_ns": 2032361379,
        "stddev_ns": 54316852,
        "avg_ts": 252.042156,
        "stddev_ts": 6.648536,
        "samples_ns": [
          1991837488,
          2011166395,
          2094080256
        ],
        "samples_ts": [
          257.049,
          254.579,
          244.499
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:30Z",
        "avg_ns": 10045437,
        "stddev_ns": 93086,
        "avg_ts": 99.553335,
        "stddev_ts": 0.916691,
        "samples_ns": [
          10152449,
          9984421,
          9999443
        ],
        "samples_ts": [
          98.4984,
          100.156,
          100.006
        ]
      }
    ],
    "scheduler": "scx_flatcg",
    "exit_code": 0
  },
  "scx_lavd": {
    "pp_tps": 251.213533,
    "tg_tps": 100.810067,
    "pp_time": 1044.734893056,
    "tg_time": 0.009921642,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:35Z",
        "avg_ns": 2040497838,
        "stddev_ns": 85063266,
        "avg_ts": 251.213533,
        "stddev_ts": 10.594577,
        "samples_ns": [
          2055741255,
          2116908790,
          1948843469
        ],
        "samples_ts": [
          249.059,
          241.862,
          262.72
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:43Z",
        "avg_ns": 9921642,
        "stddev_ns": 172935,
        "avg_ts": 100.810067,
        "stddev_ts": 1.746938,
        "samples_ns": [
          9879978,
          9773345,
          10111603
        ],
        "samples_ts": [
          101.215,
          102.319,
          98.8963
        ]
      }
    ],
    "scheduler": "scx_lavd",
    "exit_code": 0
  },
  "scx_layered": {
    "pp_tps": 274.305953,
    "tg_tps": 93.190906,
    "pp_time": 955.671882752,
    "tg_time": 0.010815023,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:50Z",
        "avg_ns": 1866546646,
        "stddev_ns": 7039329,
        "avg_ts": 274.305953,
        "stddev_ts": 1.034839,
        "samples_ns": [
          1866955299,
          1859311892,
          1873372747
        ],
        "samples_ts": [
          274.243,
          275.371,
          273.304
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:27:57Z",
        "avg_ns": 10815023,
        "stddev_ns": 1206863,
        "avg_ts": 93.190906,
        "stddev_ts": 9.771621,
        "samples_ns": [
          10089709,
          12208184,
          10147178
        ],
        "samples_ts": [
          99.1109,
          81.9123,
          98.5496
        ]
      }
    ],
    "scheduler": "scx_layered",
    "exit_code": 0
  },
  "scx_mitosis": {
    "pp_tps": 264.772013,
    "tg_tps": 86.996585,
    "pp_time": 991.924799488,
    "tg_time": 0.011583444,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:02Z",
        "avg_ns": 1937353124,
        "stddev_ns": 102705759,
        "avg_ts": 264.772013,
        "stddev_ts": 13.98158,
        "samples_ns": [
          1930476219,
          1838258655,
          2043324500
        ],
        "samples_ts": [
          265.22,
          278.524,
          250.572
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:10Z",
        "avg_ns": 11583444,
        "stddev_ns": 1210069,
        "avg_ts": 86.996585,
        "stddev_ts": 9.57522,
        "samples_ns": [
          12514481,
          12020215,
          10215638
        ],
        "samples_ts": [
          79.9074,
          83.1932,
          97.8891
        ]
      }
    ],
    "scheduler": "scx_mitosis",
    "exit_code": 0
  },
  "scx_nest": {
    "pp_tps": 246.976828,
    "tg_tps": 99.48724,
    "pp_time": 1066.331526144,
    "tg_time": 0.010056068,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:14Z",
        "avg_ns": 2082678762,
        "stddev_ns": 175907580,
        "avg_ts": 246.976828,
        "stddev_ts": 20.252965,
        "samples_ns": [
          2277664665,
          2034469155,
          1935902467
        ],
        "samples_ts": [
          224.792,
          251.663,
          264.476
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:23Z",
        "avg_ns": 10056068,
        "stddev_ns": 263110,
        "avg_ts": 99.48724,
        "stddev_ts": 2.56848,
        "samples_ns": [
          9947355,
          10356094,
          9864756
        ],
        "samples_ts": [
          100.529,
          96.5615,
          101.371
        ]
      }
    ],
    "scheduler": "scx_nest",
    "exit_code": 0
  },
  "scx_p2dq": {
    "pp_tps": 223.176601,
    "tg_tps": 99.123232,
    "pp_time": 1199.350242304,
    "tg_time": 0.010088607,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:27Z",
        "avg_ns": 2342480942,
        "stddev_ns": 429712700,
        "avg_ts": 223.176601,
        "stddev_ts": 37.72249,
        "samples_ns": [
          2176050046,
          2020877205,
          2830515575
        ],
        "samples_ts": [
          235.289,
          253.355,
          180.886
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:37Z",
        "avg_ns": 10088607,
        "stddev_ns": 48568,
        "avg_ts": 99.123232,
        "stddev_ts": 0.475473,
        "samples_ns": [
          10078137,
          10141451,
          10046234
        ],
        "samples_ts": [
          99.2247,
          98.6052,
          99.5398
        ]
      }
    ],
    "scheduler": "scx_p2dq",
    "exit_code": 0
  },
  "scx_pair": {
    "pp_tps": 171.829618,
    "tg_tps": 98.436771,
    "pp_time": 1746.053428224,
    "tg_time": 0.010158896,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:42Z",
        "avg_ns": 3410260602,
        "stddev_ns": 3406588224,
        "avg_ts": 171.829618,
        "stddev_ts": 74.253792,
        "samples_ns": [
          2058339952,
          3080883071,
          5091558785
        ],
        "samples_ts": [
          248.744,
          166.186,
          100.559
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:54Z",
        "avg_ns": 10158896,
        "stddev_ns": 37121,
        "avg_ts": 98.436771,
        "stddev_ts": 0.360304,
        "samples_ns": [
          10187723,
          10117010,
          10171955
        ],
        "samples_ts": [
          98.1574,
          98.8434,
          98.3095
        ]
      }
    ],
    "scheduler": "scx_pair",
    "exit_code": 0
  },
  "scx_prev": {
    "pp_tps": 194.479684,
    "tg_tps": 86.181439,
    "pp_time": 1614.294403072,
    "tg_time": 0.011673196,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:28:58Z",
        "avg_ns": 3152918756,
        "stddev_ns": 1782212756,
        "avg_ts": 194.479684,
        "stddev_ts": 86.192895,
        "samples_ns": [
          1929993982,
          5197776955,
          2330985333
        ],
        "samples_ts": [
          265.286,
          98.5036,
          219.65
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:29:22Z",
        "avg_ns": 11673196,
        "stddev_ns": 1135862,
        "avg_ts": 86.181439,
        "stddev_ts": 7.94048,
        "samples_ns": [
          11036562,
          12984592,
          10998434
        ],
        "samples_ts": [
          90.6079,
          77.0144,
          90.922
        ]
      }
    ],
    "scheduler": "scx_prev",
    "exit_code": 0
  },
  "scx_qmap": {
    "pp_tps": 240.201001,
    "tg_tps": 99.803915,
    "pp_time": 1096.582816256,
    "tg_time": 0.010019851,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:29:26Z",
        "avg_ns": 2141763313,
        "stddev_ns": 185065455,
        "avg_ts": 240.201001,
        "stddev_ts": 19.893602,
        "samples_ns": [
          2352695653,
          2065959913,
          2006634375
        ],
        "samples_ts": [
          217.623,
          247.827,
          255.154
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:29:35Z",
        "avg_ns": 10019851,
        "stddev_ns": 55568,
        "avg_ts": 99.803915,
        "stddev_ts": 0.551232,
        "samples_ns": [
          10082270,
          10001123,
          9976161
        ],
        "samples_ts": [
          99.184,
          99.9888,
          100.239
        ]
      }
    ],
    "scheduler": "scx_qmap",
    "exit_code": 0
  },
  "scx_rlfifo": {
    "pp_tps": 225.397709,
    "tg_tps": 99.93908,
    "pp_time": 1175.196856832,
    "tg_time": 0.010006166,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:29:39Z",
        "avg_ns": 2295306361,
        "stddev_ns": 288624362,
        "avg_ts": 225.397709,
        "stddev_ts": 27.908725,
        "samples_ns": [
          2026149713,
          2600090573,
          2259678798
        ],
        "samples_ts": [
          252.696,
          196.916,
          226.581
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:29:49Z",
        "avg_ns": 10006166,
        "stddev_ns": 32697,
        "avg_ts": 99.93908,
        "stddev_ts": 0.325237,
        "samples_ns": [
          10036570,
          9971837,
          10010092
        ],
        "samples_ts": [
          99.6356,
          100.282,
          99.8992
        ]
      }
    ],
    "scheduler": "scx_rlfifo",
    "exit_code": 0
  },
  "scx_rustland": {
    "pp_tps": 248.420258,
    "tg_tps": 97.315381,
    "pp_time": 1056.785202688,
    "tg_time": 0.0102795,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:29:53Z",
        "avg_ns": 2064033599,
        "stddev_ns": 97842795,
        "avg_ts": 248.420258,
        "stddev_ts": 11.463707,
        "samples_ns": [
          2004593840,
          2176960431,
          2010546527
        ],
        "samples_ts": [
          255.413,
          235.19,
          254.657
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:30:02Z",
        "avg_ns": 10279500,
        "stddev_ns": 237760,
        "avg_ts": 97.315381,
        "stddev_ts": 2.23045,
        "samples_ns": [
          10544065,
          10083783,
          10210653
        ],
        "samples_ts": [
          94.8401,
          99.1691,
          97.9369
        ]
      }
    ],
    "scheduler": "scx_rustland",
    "exit_code": 0
  },
  "scx_rusty": {
    "pp_tps": 3.543551,
    "tg_tps": 0.932932,
    "pp_time": 74011.094137856,
    "tg_time": 1.073332503,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:30:07Z",
        "avg_ns": 144552918238,
        "stddev_ns": 2165063496,
        "avg_ts": 3.543551,
        "stddev_ts": 0.092785,
        "samples_ns": [
          146450903391,
          146951926723,
          140255924601
        ],
        "samples_ts": [
          3.49605,
          3.48413,
          3.65047
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:39:45Z",
        "avg_ns": 1073332503,
        "stddev_ns": 48417973,
        "avg_ts": 0.932932,
        "stddev_ts": 0.041704,
        "samples_ns": [
          1029000147,
          1124999220,
          1065998142
        ],
        "samples_ts": [
          0.971817,
          0.88889,
          0.938088
        ]
      }
    ],
    "scheduler": "scx_rusty",
    "exit_code": 0
  },
  "scx_sdt": {
    "pp_tps": 234.463627,
    "tg_tps": 94.050189,
    "pp_time": 1129.329005056,
    "tg_time": 0.010636704,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:39:53Z",
        "avg_ns": 2205720713,
        "stddev_ns": 271455952,
        "avg_ts": 234.463627,
        "stddev_ts": 28.590275,
        "samples_ns": [
          1947415705,
          2488649764,
          2181096670
        ],
        "samples_ts": [
          262.913,
          205.734,
          234.744
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:40:02Z",
        "avg_ns": 10636704,
        "stddev_ns": 256964,
        "avg_ts": 94.050189,
        "stddev_ts": 2.241675,
        "samples_ns": [
          10932560,
          10508341,
          10469211
        ],
        "samples_ts": [
          91.4699,
          95.1625,
          95.5182
        ]
      }
    ],
    "scheduler": "scx_sdt",
    "exit_code": 0
  },
  "scx_simple": {
    "pp_tps": 238.182916,
    "tg_tps": 76.353241,
    "pp_time": 1103.57364224,
    "tg_time": 0.013520798,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:40:07Z",
        "avg_ns": 2155417270,
        "stddev_ns": 139230532,
        "avg_ts": 238.182916,
        "stddev_ts": 14.908543,
        "samples_ns": [
          2313857585,
          2099811454,
          2052582773
        ],
        "samples_ts": [
          221.276,
          243.831,
          249.442
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:40:16Z",
        "avg_ns": 13520798,
        "stddev_ns": 3043850,
        "avg_ts": 76.353241,
        "stddev_ts": 16.032762,
        "samples_ns": [
          16902877,
          11001406,
          12658112
        ],
        "samples_ts": [
          59.1615,
          90.8975,
          79.0007
        ]
      }
    ],
    "scheduler": "scx_simple",
    "exit_code": 0
  },
  "scx_tickless": {
    "pp_tps": 217.318512,
    "tg_tps": 77.513268,
    "pp_time": 1211.178541056,
    "tg_time": 0.013137663,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-20T07:40:20Z",
        "avg_ns": 2365583088,
        "stddev_ns": 186344014,
        "avg_ts": 217.318512,
        "stddev_ts": 16.797473,
        "samples_ns": [
          2330214232,
          2567076848,
          2199458186
        ],
        "samples_ts": [
          219.722,
          199.449,
          232.785
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 16,
        "n_ubatch": 512,
        "n_threads": 86,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-20T07:40:30Z",
        "avg_ns": 13137663,
        "stddev_ns": 2078324,
        "avg_ts": 77.513268,
        "stddev_ts": 13.258338,
        "samples_ns": [
          14777700,
          13834919,
          10800372
        ],
        "samples_ts": [
          67.6695,
          72.2809,
          92.5894
        ]
      }
    ],
    "scheduler": "scx_tickless",
    "exit_code": 0
  }
}