{
  "default": {
    "pp_tps": 138.116196,
    "tg_tps": 1.413716,
    "pp_time": 1898.006098432,
    "tg_time": 0.707359143,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:22:50Z",
        "avg_ns": 3707043161,
        "stddev_ns": 10426457,
        "avg_ts": 138.116196,
        "stddev_ts": 0.388252,
        "samples_ns": [
          3718098137,
          3705645037,
          3697386309
        ],
        "samples_ts": [
          137.705,
          138.168,
          138.476
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:23:05Z",
        "avg_ns": 707359143,
        "stddev_ns": 1900426,
        "avg_ts": 1.413716,
        "stddev_ts": 0.003792,
        "samples_ns": [
          706032119,
          706509325,
          709535986
        ],
        "samples_ts": [
          1.41637,
          1.41541,
          1.40937
        ]
      }
    ],
    "scheduler": "default",
    "exit_code": 0
  },
  "scx_bpfland": {
    "pp_tps": 129.954869,
    "tg_tps": 1.162141,
    "pp_time": 2017.322861568,
    "tg_time": 0.860540511,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:23:10Z",
        "avg_ns": 3940083714,
        "stddev_ns": 38888055,
        "avg_ts": 129.954869,
        "stddev_ts": 1.275365,
        "samples_ns": [
          3917539170,
          3917724445,
          3984987529
        ],
        "samples_ts": [
          130.694,
          130.688,
          128.482
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:23:26Z",
        "avg_ns": 860540511,
        "stddev_ns": 8762620,
        "avg_ts": 1.162141,
        "stddev_ts": 0.01185,
        "samples_ns": [
          861319317,
          868887733,
          851414483
        ],
        "samples_ts": [
          1.16101,
          1.1509,
          1.17452
        ]
      }
    ],
    "scheduler": "scx_bpfland",
    "exit_code": 0
  },
  "scx_central": {
    "pp_tps": 88.719221,
    "tg_tps": 0.889697,
    "pp_time": 2954.871065088,
    "tg_time": 1.124146052,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:23:35Z",
        "avg_ns": 5771232549,
        "stddev_ns": 43304617,
        "avg_ts": 88.719221,
        "stddev_ts": 0.666948,
        "samples_ns": [
          5810434006,
          5778515244,
          5724748398
        ],
        "samples_ts": [
          88.1173,
          88.6041,
          89.4362
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:23:58Z",
        "avg_ns": 1124146052,
        "stddev_ns": 16877929,
        "avg_ts": 0.889697,
        "stddev_ts": 0.013245,
        "samples_ns": [
          1115535932,
          1113309688,
          1143592537
        ],
        "samples_ts": [
          0.89643,
          0.898223,
          0.874437
        ]
      }
    ],
    "scheduler": "scx_central",
    "exit_code": 0
  },
  "scx_chaos": {
    "pp_tps": 128.788344,
    "tg_tps": 1.180757,
    "pp_time": 2035.4745344,
    "tg_time": 0.84691747,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:24:07Z",
        "avg_ns": 3975536200,
        "stddev_ns": 11224665,
        "avg_ts": 128.788344,
        "stddev_ts": 0.364207,
        "samples_ns": [
          3982155743,
          3981876373,
          3962576486
        ],
        "samples_ts": [
          128.574,
          128.583,
          129.209
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:24:23Z",
        "avg_ns": 846917470,
        "stddev_ns": 1987516,
        "avg_ts": 1.180757,
        "stddev_ts": 0.00277,
        "samples_ns": [
          846747085,
          848984694,
          845020631
        ],
        "samples_ts": [
          1.18099,
          1.17788,
          1.1834
        ]
      }
    ],
    "scheduler": "scx_chaos",
    "exit_code": 0
  },
  "scx_flash": {
    "pp_tps": 140.701123,
    "tg_tps": 2.419177,
    "pp_time": 1863.182910464,
    "tg_time": 0.413381387,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:24:31Z",
        "avg_ns": 3639029122,
        "stddev_ns": 24468726,
        "avg_ts": 140.701123,
        "stddev_ts": 0.949137,
        "samples_ns": [
          3611315668,
          3648123015,
          3657648685
        ],
        "samples_ts": [
          141.777,
          140.346,
          139.981
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:24:46Z",
        "avg_ns": 413381387,
        "stddev_ns": 3299317,
        "avg_ts": 2.419177,
        "stddev_ts": 0.01937,
        "samples_ns": [
          416098126,
          414336023,
          409710012
        ],
        "samples_ts": [
          2.40328,
          2.4135,
          2.44075
        ]
      }
    ],
    "scheduler": "scx_flash",
    "exit_code": 0
  },
  "scx_flatcg": {
    "pp_tps": 87.196867,
    "tg_tps": 1.223466,
    "pp_time": 5217.127234048,
    "tg_time": 0.817382192,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:24:53Z",
        "avg_ns": 10189701629,
        "stddev_ns": 3235390238,
        "avg_ts": 87.196867,
        "stddev_ts": 56.571294,
        "samples_ns": [
          21880429594,
          3900907720,
          4787767573
        ],
        "samples_ts": [
          23.3999,
          131.252,
          106.939
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:25:33Z",
        "avg_ns": 817382192,
        "stddev_ns": 6252924,
        "avg_ts": 1.223466,
        "stddev_ts": 0.009382,
        "samples_ns": [
          818747670,
          810559366,
          822839540
        ],
        "samples_ts": [
          1.22138,
          1.23372,
          1.2153
        ]
      }
    ],
    "scheduler": "scx_flatcg",
    "exit_code": 0
  },
  "scx_lavd": {
    "pp_tps": 123.344414,
    "tg_tps": 1.829002,
    "pp_time": 2125.430964736,
    "tg_time": 0.551084842,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:25:41Z",
        "avg_ns": 4151232353,
        "stddev_ns": 39851652,
        "avg_ts": 123.344414,
        "stddev_ts": 1.178942,
        "samples_ns": [
          4120131168,
          4137411336,
          4196154555
        ],
        "samples_ts": [
          124.268,
          123.749,
          122.016
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:25:58Z",
        "avg_ns": 551084842,
        "stddev_ns": 58046205,
        "avg_ts": 1.829002,
        "stddev_ts": 0.205067,
        "samples_ns": [
          586555948,
          484097779,
          582600801
        ],
        "samples_ts": [
          1.70487,
          2.0657,
          1.71644
        ]
      }
    ],
    "scheduler": "scx_lavd",
    "exit_code": 0
  },
  "scx_layered": {
    "pp_tps": 124.839866,
    "tg_tps": 2.448387,
    "pp_time": 2099.872710144,
    "tg_time": 0.420639617,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:26:06Z",
        "avg_ns": 4101313887,
        "stddev_ns": 19196405,
        "avg_ts": 124.839866,
        "stddev_ts": 0.584195,
        "samples_ns": [
          4082415305,
          4100731905,
          4120794453
        ],
        "samples_ts": [
          125.416,
          124.856,
          124.248
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:26:22Z",
        "avg_ns": 420639617,
        "stddev_ns": 92592801,
        "avg_ts": 2.448387,
        "stddev_ts": 0.485021,
        "samples_ns": [
          526516487,
          380584991,
          354817375
        ],
        "samples_ts": [
          1.89928,
          2.62753,
          2.81835
        ]
      }
    ],
    "scheduler": "scx_layered",
    "exit_code": 0
  },
  "scx_mitosis": {
    "pp_tps": 138.910665,
    "tg_tps": 1.359327,
    "pp_time": 1887.152735744,
    "tg_time": 0.735709697,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:26:29Z",
        "avg_ns": 3685845187,
        "stddev_ns": 11301166,
        "avg_ts": 138.910665,
        "stddev_ts": 0.425418,
        "samples_ns": [
          3698374192,
          3676420877,
          3682740492
        ],
        "samples_ts": [
          138.439,
          139.266,
          139.027
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:26:44Z",
        "avg_ns": 735709697,
        "stddev_ns": 7543832,
        "avg_ts": 1.359327,
        "stddev_ts": 0.013869,
        "samples_ns": [
          744266233,
          730017940,
          732844919
        ],
        "samples_ts": [
          1.34361,
          1.36983,
          1.36455
        ]
      }
    ],
    "scheduler": "scx_mitosis",
    "exit_code": 0
  },
  "scx_nest": {
    "pp_tps": 119.358888,
    "tg_tps": 2.197161,
    "pp_time": 2196.328686592,
    "tg_time": 0.455553347,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:26:51Z",
        "avg_ns": 4289704466,
        "stddev_ns": 27840311,
        "avg_ts": 119.358888,
        "stddev_ts": 0.773357,
        "samples_ns": [
          4284753079,
          4264672134,
          4319688186
        ],
        "samples_ts": [
          119.493,
          120.056,
          118.527
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:27:09Z",
        "avg_ns": 455553347,
        "stddev_ns": 16843861,
        "avg_ts": 2.197161,
        "stddev_ts": 0.082302,
        "samples_ns": [
          437063202,
          459573419,
          470023422
        ],
        "samples_ts": [
          2.288,
          2.17593,
          2.12755
        ]
      }
    ],
    "scheduler": "scx_nest",
    "exit_code": 0
  },
  "scx_p2dq": {
    "pp_tps": 133.552311,
    "tg_tps": 1.270028,
    "pp_time": 1962.871588864,
    "tg_time": 0.787414611,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:27:15Z",
        "avg_ns": 3833733572,
        "stddev_ns": 13081699,
        "avg_ts": 133.552311,
        "stddev_ts": 0.456193,
        "samples_ns": [
          3819460033,
          3836589836,
          3845150849
        ],
        "samples_ts": [
          134.05,
          133.452,
          133.155
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:27:31Z",
        "avg_ns": 787414611,
        "stddev_ns": 6026446,
        "avg_ts": 1.270028,
        "stddev_ts": 0.009687,
        "samples_ns": [
          794193599,
          785385730,
          782664505
        ],
        "samples_ts": [
          1.25914,
          1.27326,
          1.27769
        ]
      }
    ],
    "scheduler": "scx_p2dq",
    "exit_code": 0
  },
  "scx_pair": {
    "pp_tps": 133.741737,
    "tg_tps": 1.413663,
    "pp_time": 1961.532585472,
    "tg_time": 0.707398229,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:27:40Z",
        "avg_ns": 3831118331,
        "stddev_ns": 127503348,
        "avg_ts": 133.741737,
        "stddev_ts": 4.476174,
        "samples_ns": [
          3844288384,
          3951525465,
          3697541146
        ],
        "samples_ts": [
          133.185,
          129.57,
          138.47
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:27:55Z",
        "avg_ns": 707398229,
        "stddev_ns": 4118216,
        "avg_ts": 1.413663,
        "stddev_ts": 0.008228,
        "samples_ns": [
          711569998,
          703335920,
          707288770
        ],
        "samples_ts": [
          1.40534,
          1.4218,
          1.41385
        ]
      }
    ],
    "scheduler": "scx_pair",
    "exit_code": 0
  },
  "scx_prev": {
    "pp_tps": 143.64943,
    "tg_tps": 1.469006,
    "pp_time": 1824.88733696,
    "tg_time": 0.680733115,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:28:02Z",
        "avg_ns": 3564233080,
        "stddev_ns": 1374045,
        "avg_ts": 143.64943,
        "stddev_ts": 0.055387,
        "samples_ns": [
          3565359263,
          3564637865,
          3562702112
        ],
        "samples_ts": [
          143.604,
          143.633,
          143.711
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:28:17Z",
        "avg_ns": 680733115,
        "stddev_ns": 867839,
        "avg_ts": 1.469006,
        "stddev_ts": 0.001872,
        "samples_ns": [
          681554400,
          680819045,
          679825901
        ],
        "samples_ts": [
          1.46723,
          1.46882,
          1.47096
        ]
      }
    ],
    "scheduler": "scx_prev",
    "exit_code": 0
  },
  "scx_qmap": {
    "pp_tps": 136.296599,
    "tg_tps": 1.397972,
    "pp_time": 1923.342564864,
    "tg_time": 0.715344704,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:28:24Z",
        "avg_ns": 3756528447,
        "stddev_ns": 9210223,
        "avg_ts": 136.296599,
        "stddev_ts": 0.333905,
        "samples_ns": [
          3766587895,
          3754487050,
          3748510397
        ],
        "samples_ts": [
          135.932,
          136.37,
          136.588
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:28:40Z",
        "avg_ns": 715344704,
        "stddev_ns": 4942295,
        "avg_ts": 1.397972,
        "stddev_ts": 0.009622,
        "samples_ns": [
          721015722,
          711956070,
          713062320
        ],
        "samples_ts": [
          1.38693,
          1.40458,
          1.4024
        ]
      }
    ],
    "scheduler": "scx_qmap",
    "exit_code": 0
  },
  "scx_rlfifo": {
    "pp_tps": 113.237198,
    "tg_tps": 1.143017,
    "pp_time": 2319.869339136,
    "tg_time": 0.874964298,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:28:47Z",
        "avg_ns": 4530994803,
        "stddev_ns": 251184606,
        "avg_ts": 113.237198,
        "stddev_ts": 6.43388,
        "samples_ns": [
          4732980421,
          4249738120,
          4610265868
        ],
        "samples_ts": [
          108.177,
          120.478,
          111.057
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:29:05Z",
        "avg_ns": 874964298,
        "stddev_ns": 10651765,
        "avg_ts": 1.143017,
        "stddev_ts": 0.013935,
        "samples_ns": [
          875746820,
          863942934,
          885203142
        ],
        "samples_ts": [
          1.14188,
          1.15748,
          1.12968
        ]
      }
    ],
    "scheduler": "scx_rlfifo",
    "exit_code": 0
  },
  "scx_rustland": {
    "pp_tps": 92.671912,
    "tg_tps": 1.002779,
    "pp_time": 2838.525426176,
    "tg_time": 0.997423813,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:29:13Z",
        "avg_ns": 5543994973,
        "stddev_ns": 3063170939,
        "avg_ts": 92.671912,
        "stddev_ts": 6.660435,
        "samples_ns": [
          5524211012,
          5154699519,
          5953074389
        ],
        "samples_ts": [
          92.6829,
          99.3268,
          86.006
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:29:36Z",
        "avg_ns": 997423813,
        "stddev_ns": 17054516,
        "avg_ts": 1.002779,
        "stddev_ts": 0.017215,
        "samples_ns": [
          979194323,
          1000087138,
          1012989978
        ],
        "samples_ts": [
          1.02125,
          0.999913,
          0.987177
        ]
      }
    ],
    "scheduler": "scx_rustland",
    "exit_code": 0
  },
  "scx_rusty": {
    "pp_tps": 132.806674,
    "tg_tps": 1.207626,
    "pp_time": 1973.901766144,
    "tg_time": 0.828077777,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:29:44Z",
        "avg_ns": 3855276887,
        "stddev_ns": 16809495,
        "avg_ts": 132.806674,
        "stddev_ts": 0.579937,
        "samples_ns": [
          3836774617,
          3859448181,
          3869607864
        ],
        "samples_ts": [
          133.445,
          132.661,
          132.313
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:30:00Z",
        "avg_ns": 828077777,
        "stddev_ns": 2927331,
        "avg_ts": 1.207626,
        "stddev_ts": 0.004271,
        "samples_ns": [
          830858861,
          825023868,
          828350604
        ],
        "samples_ts": [
          1.20357,
          1.21209,
          1.20722
        ]
      }
    ],
    "scheduler": "scx_rusty",
    "exit_code": 0
  },
  "scx_sdt": {
    "pp_tps": 140.105531,
    "tg_tps": 1.287575,
    "pp_time": 1871.06164992,
    "tg_time": 0.776713688,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:30:08Z",
        "avg_ns": 3654417285,
        "stddev_ns": 12630358,
        "avg_ts": 140.105531,
        "stddev_ts": 0.483766,
        "samples_ns": [
          3643188937,
          3651971117,
          3668091801
        ],
        "samples_ts": [
          140.536,
          140.198,
          139.582
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:30:23Z",
        "avg_ns": 776713688,
        "stddev_ns": 8365044,
        "avg_ts": 1.287575,
        "stddev_ts": 0.013868,
        "samples_ns": [
          785070841,
          776729358,
          768340866
        ],
        "samples_ts": [
          1.27377,
          1.28745,
          1.30151
        ]
      }
    ],
    "scheduler": "scx_sdt",
    "exit_code": 0
  },
  "scx_simple": {
    "pp_tps": 140.895448,
    "tg_tps": 1.34033,
    "pp_time": 1860.557684224,
    "tg_time": 0.746091019,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:30:30Z",
        "avg_ns": 3633901727,
        "stddev_ns": 2855153,
        "avg_ts": 140.895448,
        "stddev_ts": 0.110627,
        "samples_ns": [
          3632266173,
          3632241201,
          3637197808
        ],
        "samples_ts": [
          140.959,
          140.96,
          140.768
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:30:45Z",
        "avg_ns": 746091019,
        "stddev_ns": 2621451,
        "avg_ts": 1.34033,
        "stddev_ts": 0.004702,
        "samples_ns": [
          744058703,
          745164427,
          749049927
        ],
        "samples_ts": [
          1.34398,
          1.34199,
          1.33502
        ]
      }
    ],
    "scheduler": "scx_simple",
    "exit_code": 0
  },
  "scx_tickless": {
    "pp_tps": 103.98023,
    "tg_tps": 1.27402,
    "pp_time": 2521.138177024,
    "tg_time": 0.785054889,
    "raw_output": [
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 512,
        "n_gen": 0,
        "n_depth": 0,
        "test_time": "2025-08-16T14:30:53Z",
        "avg_ns": 4924098002,
        "stddev_ns": 25048387,
        "avg_ts": 103.98023,
        "stddev_ts": 0.529417,
        "samples_ns": [
          4947524260,
          4897693735,
          4927076011
        ],
        "samples_ts": [
          103.486,
          104.539,
          103.916
        ]
      },
      {
        "build_commit": "5aa1105d",
        "build_number": 6082,
        "cpu_info": "Intel(R) Xeon(R) 6787P",
        "gpu_info": "",
        "backends": "CPU",
        "model_filename": "/root/yunwei37/ai-os/workloads/llama.cpp/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        "model_type": "llama 1B Q4_K - Medium",
        "model_size": 667078656,
        "model_n_params": 1100048384,
        "n_batch": 512,
        "n_ubatch": 512,
        "n_threads": 128,
        "cpu_mask": "0x0",
        "cpu_strict": false,
        "poll": 50,
        "type_k": "f16",
        "type_v": "f16",
        "n_gpu_layers": 99,
        "split_mode": "layer",
        "main_gpu": 0,
        "no_kv_offload": false,
        "flash_attn": false,
        "tensor_split": "0.00",
        "tensor_buft_overrides": "none",
        "defrag_thold": -1.0,
        "use_mmap": true,
        "embeddings": false,
        "no_op_offload": 0,
        "n_prompt": 0,
        "n_gen": 1,
        "n_depth": 0,
        "test_time": "2025-08-16T14:31:13Z",
        "avg_ns": 785054889,
        "stddev_ns": 12741378,
        "avg_ts": 1.27402,
        "stddev_ts": 0.020705,
        "samples_ns": [
          772007815,
          797466748,
          785690105
        ],
        "samples_ts": [
          1.29532,
          1.25397,
          1.27277
        ]
      }
    ],
    "scheduler": "scx_tickless",
    "exit_code": 0
  },
  "scx_userland": {
    "scheduler": "scx_userland",
    "error": "Command timed out",
    "exit_code": -1
  }
}