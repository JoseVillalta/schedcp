# llama

## gpt-oss-120b

llama.cpp/build/bin/llama-server -hf unsloth/gpt-oss-120b-GGUF:Q4_K_M